INFO:niftynet:2019-02-11 14:09:45,619: set CUDA_VISIBLE_DEVICES to 0
INFO:niftynet:2019-02-11 14:09:45,620: starting segmentation application
INFO:niftynet:2019-02-11 14:09:45,620: [T1] using existing csv file /home/sathiesh/niftynet_brain/csv/brats/orig_t1.csv, skipped filenames search
INFO:niftynet:2019-02-11 14:09:45,625: [T2] using existing csv file /home/sathiesh/niftynet_brain/csv/brats/orig_t2.csv, skipped filenames search
INFO:niftynet:2019-02-11 14:09:45,629: [label] using existing csv file /home/sathiesh/niftynet_brain/csv/brats/labels.csv, skipped filenames search
INFO:niftynet:2019-02-11 14:09:45,635: 

Number of subjects 285, input section names: ['subject_id', 'T1', 'T2', 'label']
Dataset partitioning:
-- training 227 cases (79.65%),
-- validation 29 cases (10.18%),
-- inference 29 cases (10.18%).

INFO:niftynet:2019-02-11 14:10:04,766: Image reader: loading 227 subjects from sections ('T1', 'T2') as input [image]
INFO:niftynet:2019-02-11 14:10:04,766: Image reader: loading 227 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-02-11 14:10:06,581: Image reader: loading 29 subjects from sections ('T1', 'T2') as input [image]
INFO:niftynet:2019-02-11 14:10:06,581: Image reader: loading 29 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-02-11 14:10:06,582: training normalisation histogram references for image:{'T1', 'T2'}, using 227 subjects
INFO:niftynet:2019-02-11 14:15:38,892: Looking for the set of unique discrete labels from input label using 227 subjects
WARNING:niftynet:2019-02-11 14:16:32,966: moved existing histogram reference file
 from /home/sathiesh/niftynet_brain/models/brats/label_mapping_whole_tumor.txt to /home/sathiesh/niftynet_brain/models/brats/label_mapping_whole_tumor.txt.backup
INFO:niftynet:2019-02-11 14:16:32,967: normalisation histogram reference models ready for image:('T1', 'T2')
INFO:niftynet:2019-02-11 14:16:32,967: label mapping ready for label:('label',), 4 classes
INFO:niftynet:2019-02-11 14:16:34,159: initialised uniform sampler {'image': (1, 120, 120, 80, 1, 2), 'image_location': (1, 7), 'label': (1, 120, 120, 80, 1, 1), 'label_location': (1, 7)} 
INFO:niftynet:2019-02-11 14:16:34,219: initialised uniform sampler {'image': (1, 120, 120, 80, 1, 2), 'image_location': (1, 7), 'label': (1, 120, 120, 80, 1, 1), 'label_location': (1, 7)} 
WARNING:niftynet:2019-02-11 14:16:34,283: From /home/sathiesh/niftynet_brain/NiftyNet/niftynet/engine/application_initializer.py:106: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
INFO:niftynet:2019-02-11 14:16:34,283: using DenseVNet
INFO:niftynet:2019-02-11 14:16:34,288: Initialising Dataset from 227 subjects...
INFO:niftynet:2019-02-11 14:16:34,327: Initialising Dataset from 29 subjects...
INFO:niftynet:2019-02-11 14:16:45,123: Parameters from random initialisations ...
INFO:niftynet:2019-02-11 14:18:40,330: training iter 1, loss=0.864195704460144 (114.881851s)
INFO:niftynet:2019-02-11 14:18:41,535: training iter 2, loss=0.7888679504394531 (1.204962s)
INFO:niftynet:2019-02-11 14:18:49,683: training iter 3, loss=0.7635104656219482 (8.146882s)
INFO:niftynet:2019-02-11 14:18:51,251: training iter 4, loss=0.7774174213409424 (1.567912s)
INFO:niftynet:2019-02-11 14:19:00,665: training iter 5, loss=0.6828439235687256 (9.413181s)
INFO:niftynet:2019-02-11 14:19:02,290: training iter 6, loss=0.7597585916519165 (1.618699s)
INFO:niftynet:2019-02-11 14:19:07,335: training iter 7, loss=0.7359485626220703 (5.044523s)
INFO:niftynet:2019-02-11 14:19:12,608: training iter 8, loss=0.6956263780593872 (5.272382s)
INFO:niftynet:2019-02-11 14:19:15,945: training iter 9, loss=0.657566487789154 (3.336561s)
INFO:niftynet:2019-02-11 14:19:18,403: training iter 10, loss=0.687290370464325 (2.456562s)
INFO:niftynet:2019-02-11 14:20:09,415:     validation iter 10, loss=0.7482191324234009 (51.009710s)
INFO:niftynet:2019-02-11 14:20:11,137: training iter 11, loss=0.7230434417724609 (1.683651s)
WARNING:niftynet:2019-02-11 14:20:13,515: User cancelled application
INFO:niftynet:2019-02-11 14:20:13,516: cleaning up...
INFO:niftynet:2019-02-11 14:20:13,516: stopping sampling threads
INFO:niftynet:2019-02-11 14:20:15,260: iter 12 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
WARNING:niftynet:2019-02-11 14:20:50,685: stopped early, incomplete iterations.
INFO:niftynet:2019-02-11 14:20:50,685: SegmentationApplication stopped (time in second 246.45).
INFO:niftynet:2019-02-11 14:50:05,931: set CUDA_VISIBLE_DEVICES to 0
INFO:niftynet:2019-02-11 14:50:05,931: starting segmentation application
INFO:niftynet:2019-02-11 14:50:05,931: [T1] using existing csv file /home/sathiesh/niftynet_brain/csv/brats/orig_t1.csv, skipped filenames search
INFO:niftynet:2019-02-11 14:50:05,938: [T2] using existing csv file /home/sathiesh/niftynet_brain/csv/brats/orig_t2.csv, skipped filenames search
INFO:niftynet:2019-02-11 14:50:05,942: [label] using existing csv file /home/sathiesh/niftynet_brain/csv/brats/labels.csv, skipped filenames search
WARNING:niftynet:2019-02-11 14:50:05,946: Loading from existing partitioning file /home/sathiesh/niftynet_brain/models/brats/dataset_split.csv, ignoring partitioning ratios.
INFO:niftynet:2019-02-11 14:50:05,948: 

Number of subjects 285, input section names: ['subject_id', 'T1', 'T2', 'label']
Dataset partitioning:
-- training 227 cases (79.65%),
-- validation 29 cases (10.18%),
-- inference 29 cases (10.18%).

INFO:niftynet:2019-02-11 14:50:26,438: Image reader: loading 227 subjects from sections ('T1', 'T2') as input [image]
INFO:niftynet:2019-02-11 14:50:26,438: Image reader: loading 227 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-02-11 14:50:28,895: Image reader: loading 29 subjects from sections ('T1', 'T2') as input [image]
INFO:niftynet:2019-02-11 14:50:28,895: Image reader: loading 29 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-02-11 14:50:28,899: normalisation histogram reference models ready for image:('T1', 'T2')
INFO:niftynet:2019-02-11 14:50:28,899: Looking for the set of unique discrete labels from input label using 227 subjects
WARNING:niftynet:2019-02-11 14:51:27,097: moved existing histogram reference file
 from /home/sathiesh/niftynet_brain/models/brats/label_mapping_whole_tumor.txt to /home/sathiesh/niftynet_brain/models/brats/label_mapping_whole_tumor.txt.backup
INFO:niftynet:2019-02-11 14:51:27,098: normalisation histogram reference models ready for image:('T1', 'T2')
INFO:niftynet:2019-02-11 14:51:27,098: label mapping ready for label:('label',), 4 classes
INFO:niftynet:2019-02-11 14:51:28,547: initialised uniform sampler {'image': (1, 120, 120, 80, 1, 2), 'image_location': (1, 7), 'label': (1, 120, 120, 80, 1, 1), 'label_location': (1, 7)} 
INFO:niftynet:2019-02-11 14:51:28,600: initialised uniform sampler {'image': (1, 120, 120, 80, 1, 2), 'image_location': (1, 7), 'label': (1, 120, 120, 80, 1, 1), 'label_location': (1, 7)} 
WARNING:niftynet:2019-02-11 14:51:28,730: From /home/sathiesh/niftynet_brain/NiftyNet/niftynet/engine/application_initializer.py:106: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
INFO:niftynet:2019-02-11 14:51:28,731: using DenseVNet
INFO:niftynet:2019-02-11 14:51:28,738: Initialising Dataset from 227 subjects...
INFO:niftynet:2019-02-11 14:51:28,793: Initialising Dataset from 29 subjects...
INFO:niftynet:2019-02-11 14:51:40,063: Parameters from random initialisations ...
INFO:niftynet:2019-02-11 14:53:38,887: training iter 1, loss=0.8213201761245728 (118.823635s)
INFO:niftynet:2019-02-11 14:53:40,149: training iter 2, loss=0.8130183219909668 (1.262436s)
INFO:niftynet:2019-02-11 14:53:41,588: training iter 3, loss=0.7872865200042725 (1.438189s)
INFO:niftynet:2019-02-11 14:53:52,906: training iter 4, loss=0.7849753499031067 (11.317401s)
INFO:niftynet:2019-02-11 14:54:02,122: training iter 5, loss=0.783721387386322 (9.215170s)
INFO:niftynet:2019-02-11 14:54:03,310: training iter 6, loss=0.7042102813720703 (1.181725s)
INFO:niftynet:2019-02-11 14:54:04,733: training iter 7, loss=0.741198718547821 (1.422338s)
INFO:niftynet:2019-02-11 14:54:08,819: training iter 8, loss=0.7700908184051514 (4.085574s)
INFO:niftynet:2019-02-11 14:54:18,108: training iter 9, loss=0.7651957273483276 (9.288411s)
INFO:niftynet:2019-02-11 14:54:19,990: training iter 10, loss=0.722139835357666 (1.881084s)
INFO:niftynet:2019-02-11 14:55:19,408:     validation iter 10, loss=0.6936758160591125 (59.415054s)
INFO:niftynet:2019-02-11 14:55:25,146: training iter 11, loss=0.71181321144104 (5.685498s)
INFO:niftynet:2019-02-11 14:55:26,530: training iter 12, loss=0.764747142791748 (1.382995s)
INFO:niftynet:2019-02-11 14:55:28,072: training iter 13, loss=0.6882402896881104 (1.541363s)
INFO:niftynet:2019-02-11 14:55:29,477: training iter 14, loss=0.6422589421272278 (1.405374s)
INFO:niftynet:2019-02-11 14:55:30,996: training iter 15, loss=0.6003744006156921 (1.517602s)
INFO:niftynet:2019-02-11 14:55:32,972: training iter 16, loss=0.703515887260437 (1.966774s)
INFO:niftynet:2019-02-11 14:55:35,119: training iter 17, loss=0.678791344165802 (2.146873s)
INFO:niftynet:2019-02-11 14:55:41,374: training iter 18, loss=0.716632068157196 (6.255010s)
INFO:niftynet:2019-02-11 14:55:50,525: training iter 19, loss=0.6906520128250122 (9.146338s)
INFO:niftynet:2019-02-11 14:55:53,725: training iter 20, loss=0.7294518947601318 (3.198273s)
INFO:niftynet:2019-02-11 14:55:56,987:     validation iter 20, loss=0.6589868068695068 (3.257422s)
INFO:niftynet:2019-02-11 14:56:00,413: training iter 21, loss=0.6846651434898376 (3.425846s)
INFO:niftynet:2019-02-11 14:56:01,611: training iter 22, loss=0.7334507703781128 (1.197866s)
INFO:niftynet:2019-02-11 14:56:06,727: training iter 23, loss=0.6736185550689697 (5.114314s)
INFO:niftynet:2019-02-11 14:56:08,088: training iter 24, loss=0.7270682454109192 (1.360440s)
INFO:niftynet:2019-02-11 14:56:19,695: iter 25 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 14:56:19,695: training iter 25, loss=0.6921275854110718 (10.322076s)
INFO:niftynet:2019-02-11 14:56:21,607: training iter 26, loss=0.5853880047798157 (1.911469s)
INFO:niftynet:2019-02-11 14:56:31,186: training iter 27, loss=0.6917005777359009 (9.578339s)
INFO:niftynet:2019-02-11 14:56:32,462: training iter 28, loss=0.7021441459655762 (1.276276s)
INFO:niftynet:2019-02-11 14:56:41,897: training iter 29, loss=0.602625846862793 (9.433990s)
INFO:niftynet:2019-02-11 14:56:43,279: training iter 30, loss=0.6886136531829834 (1.379989s)
INFO:niftynet:2019-02-11 14:56:44,415:     validation iter 30, loss=0.5619261264801025 (1.134367s)
INFO:niftynet:2019-02-11 14:56:50,125: training iter 31, loss=0.6100460886955261 (5.706247s)
INFO:niftynet:2019-02-11 14:56:52,469: training iter 32, loss=0.6692713499069214 (2.343748s)
INFO:niftynet:2019-02-11 14:57:00,048: training iter 33, loss=0.6584256887435913 (7.578346s)
INFO:niftynet:2019-02-11 14:57:02,559: training iter 34, loss=0.7197336554527283 (2.509765s)
INFO:niftynet:2019-02-11 14:57:09,897: training iter 35, loss=0.6866310238838196 (7.336906s)
INFO:niftynet:2019-02-11 14:57:17,552: training iter 36, loss=0.6612006425857544 (7.653750s)
INFO:niftynet:2019-02-11 14:57:20,821: training iter 37, loss=0.6212636828422546 (3.268482s)
INFO:niftynet:2019-02-11 14:57:26,482: training iter 38, loss=0.7059299945831299 (5.661671s)
INFO:niftynet:2019-02-11 14:57:31,086: training iter 39, loss=0.6037161350250244 (4.603280s)
INFO:niftynet:2019-02-11 14:57:40,052: training iter 40, loss=0.6448420286178589 (8.964781s)
INFO:niftynet:2019-02-11 14:57:40,876:     validation iter 40, loss=0.7092901468276978 (0.821201s)
INFO:niftynet:2019-02-11 14:57:42,797: training iter 41, loss=0.6876298785209656 (1.917696s)
INFO:niftynet:2019-02-11 14:57:49,692: training iter 42, loss=0.5805675983428955 (6.893834s)
INFO:niftynet:2019-02-11 14:57:50,895: training iter 43, loss=0.6041395664215088 (1.203038s)
INFO:niftynet:2019-02-11 14:57:57,008: training iter 44, loss=0.6317375302314758 (6.113043s)
INFO:niftynet:2019-02-11 14:58:06,095: training iter 45, loss=0.7624219655990601 (9.085786s)
INFO:niftynet:2019-02-11 14:58:09,325: training iter 46, loss=0.5902621746063232 (3.228749s)
INFO:niftynet:2019-02-11 14:58:10,854: training iter 47, loss=0.7180777788162231 (1.528556s)
INFO:niftynet:2019-02-11 14:58:21,456: training iter 48, loss=0.6610220670700073 (10.601966s)
INFO:niftynet:2019-02-11 14:58:25,913: training iter 49, loss=0.6158545613288879 (4.456419s)
INFO:niftynet:2019-02-11 14:58:32,514: iter 50 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 14:58:32,514: training iter 50, loss=0.6276080012321472 (5.330141s)
INFO:niftynet:2019-02-11 14:58:33,644:     validation iter 50, loss=0.6590361595153809 (1.128084s)
INFO:niftynet:2019-02-11 14:58:35,335: training iter 51, loss=0.7590441703796387 (1.690665s)
INFO:niftynet:2019-02-11 14:58:44,253: training iter 52, loss=0.6245853900909424 (8.918257s)
INFO:niftynet:2019-02-11 14:58:45,355: training iter 53, loss=0.648145318031311 (1.102016s)
INFO:niftynet:2019-02-11 14:58:52,365: training iter 54, loss=0.5702509880065918 (7.008658s)
INFO:niftynet:2019-02-11 14:58:57,651: training iter 55, loss=0.5989841818809509 (5.285723s)
INFO:niftynet:2019-02-11 14:59:04,120: training iter 56, loss=0.5881906747817993 (6.466758s)
INFO:niftynet:2019-02-11 14:59:08,076: training iter 57, loss=0.6294103264808655 (3.955333s)
INFO:niftynet:2019-02-11 14:59:17,642: training iter 58, loss=0.6250167489051819 (9.565049s)
INFO:niftynet:2019-02-11 14:59:18,727: training iter 59, loss=0.71300208568573 (1.085110s)
INFO:niftynet:2019-02-11 14:59:21,729: training iter 60, loss=0.7133301496505737 (2.999808s)
INFO:niftynet:2019-02-11 14:59:22,526:     validation iter 60, loss=0.6906479001045227 (0.794730s)
INFO:niftynet:2019-02-11 14:59:32,350: training iter 61, loss=0.7520793676376343 (9.821962s)
INFO:niftynet:2019-02-11 14:59:38,606: training iter 62, loss=0.583608865737915 (6.254944s)
INFO:niftynet:2019-02-11 14:59:39,729: training iter 63, loss=0.5604966878890991 (1.122202s)
INFO:niftynet:2019-02-11 14:59:40,962: training iter 64, loss=0.6545993089675903 (1.232422s)
INFO:niftynet:2019-02-11 14:59:57,399: training iter 65, loss=0.6142733693122864 (16.435916s)
INFO:niftynet:2019-02-11 14:59:58,617: training iter 66, loss=0.6407320499420166 (1.216852s)
INFO:niftynet:2019-02-11 15:00:03,532: training iter 67, loss=0.6358520984649658 (4.914315s)
INFO:niftynet:2019-02-11 15:00:04,917: training iter 68, loss=0.6299670934677124 (1.384655s)
INFO:niftynet:2019-02-11 15:00:19,527: training iter 69, loss=0.7564445734024048 (14.609710s)
INFO:niftynet:2019-02-11 15:00:20,844: training iter 70, loss=0.6200591921806335 (1.315936s)
INFO:niftynet:2019-02-11 15:00:21,731:     validation iter 70, loss=0.7340951561927795 (0.885942s)
INFO:niftynet:2019-02-11 15:00:23,054: training iter 71, loss=0.6345845460891724 (1.312078s)
INFO:niftynet:2019-02-11 15:00:24,673: training iter 72, loss=0.6197923421859741 (1.618447s)
INFO:niftynet:2019-02-11 15:00:35,889: training iter 73, loss=0.7180089950561523 (11.215326s)
INFO:niftynet:2019-02-11 15:00:38,058: training iter 74, loss=0.6004767417907715 (2.168161s)
INFO:niftynet:2019-02-11 15:00:47,463: iter 75 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:00:47,463: training iter 75, loss=0.7070152759552002 (8.105005s)
INFO:niftynet:2019-02-11 15:00:49,648: training iter 76, loss=0.651875376701355 (2.184653s)
INFO:niftynet:2019-02-11 15:00:52,493: training iter 77, loss=0.6361161470413208 (2.844555s)
INFO:niftynet:2019-02-11 15:01:01,920: training iter 78, loss=0.6368155479431152 (9.425504s)
INFO:niftynet:2019-02-11 15:01:05,069: training iter 79, loss=0.6077585220336914 (3.147670s)
INFO:niftynet:2019-02-11 15:01:13,060: training iter 80, loss=0.6244897246360779 (7.986753s)
INFO:niftynet:2019-02-11 15:01:13,980:     validation iter 80, loss=0.6034918427467346 (0.917431s)
INFO:niftynet:2019-02-11 15:01:15,049: training iter 81, loss=0.5917991995811462 (1.066276s)
INFO:niftynet:2019-02-11 15:01:19,352: training iter 82, loss=0.6569010019302368 (4.303364s)
INFO:niftynet:2019-02-11 15:01:25,642: training iter 83, loss=0.769134521484375 (6.287934s)
INFO:niftynet:2019-02-11 15:01:35,776: training iter 84, loss=0.6337131261825562 (10.134218s)
INFO:niftynet:2019-02-11 15:01:37,107: training iter 85, loss=0.5291855931282043 (1.329465s)
INFO:niftynet:2019-02-11 15:01:38,716: training iter 86, loss=0.638177216053009 (1.606471s)
INFO:niftynet:2019-02-11 15:01:45,843: training iter 87, loss=0.710107147693634 (7.121500s)
INFO:niftynet:2019-02-11 15:01:53,714: training iter 88, loss=0.5928430557250977 (7.870748s)
INFO:niftynet:2019-02-11 15:01:59,654: training iter 89, loss=0.6014253497123718 (5.939987s)
INFO:niftynet:2019-02-11 15:02:00,959: training iter 90, loss=0.6023451685905457 (1.302466s)
INFO:niftynet:2019-02-11 15:02:11,258:     validation iter 90, loss=0.7187318801879883 (10.296247s)
INFO:niftynet:2019-02-11 15:02:16,230: training iter 91, loss=0.7156481742858887 (4.970812s)
INFO:niftynet:2019-02-11 15:02:24,106: training iter 92, loss=0.6926436424255371 (7.876208s)
INFO:niftynet:2019-02-11 15:02:25,024: training iter 93, loss=0.6558632850646973 (0.918092s)
INFO:niftynet:2019-02-11 15:02:26,026: training iter 94, loss=0.5252622365951538 (1.000774s)
INFO:niftynet:2019-02-11 15:02:32,102: training iter 95, loss=0.5478583574295044 (6.075040s)
INFO:niftynet:2019-02-11 15:02:36,323: training iter 96, loss=0.7440988421440125 (4.219125s)
INFO:niftynet:2019-02-11 15:02:55,669: training iter 97, loss=0.6276537179946899 (19.345423s)
INFO:niftynet:2019-02-11 15:02:56,885: training iter 98, loss=0.7007743716239929 (1.216244s)
INFO:niftynet:2019-02-11 15:02:59,580: training iter 99, loss=0.5905880331993103 (2.694798s)
INFO:niftynet:2019-02-11 15:03:02,289: iter 100 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:03:02,290: training iter 100, loss=0.6700689196586609 (1.500415s)
INFO:niftynet:2019-02-11 15:03:03,405:     validation iter 100, loss=0.6096750497817993 (1.114239s)
INFO:niftynet:2019-02-11 15:03:14,260: training iter 101, loss=0.5622483491897583 (10.852397s)
INFO:niftynet:2019-02-11 15:03:17,348: training iter 102, loss=0.7205313444137573 (3.087870s)
INFO:niftynet:2019-02-11 15:03:20,873: training iter 103, loss=0.6706246137619019 (3.522964s)
INFO:niftynet:2019-02-11 15:03:28,685: training iter 104, loss=0.646285355091095 (7.812485s)
INFO:niftynet:2019-02-11 15:03:35,554: training iter 105, loss=0.5407096147537231 (6.867800s)
INFO:niftynet:2019-02-11 15:03:42,791: training iter 106, loss=0.7018704414367676 (7.234889s)
INFO:niftynet:2019-02-11 15:03:43,664: training iter 107, loss=0.7362150549888611 (0.872579s)
INFO:niftynet:2019-02-11 15:03:46,831: training iter 108, loss=0.6409047842025757 (3.167399s)
INFO:niftynet:2019-02-11 15:03:55,721: training iter 109, loss=0.5130786895751953 (8.889478s)
INFO:niftynet:2019-02-11 15:04:02,097: training iter 110, loss=0.6366565823554993 (6.375037s)
INFO:niftynet:2019-02-11 15:04:03,257:     validation iter 110, loss=0.7656654715538025 (1.157917s)
INFO:niftynet:2019-02-11 15:04:04,893: training iter 111, loss=0.7643023729324341 (1.628741s)
INFO:niftynet:2019-02-11 15:04:06,269: training iter 112, loss=0.6124044060707092 (1.375228s)
INFO:niftynet:2019-02-11 15:04:19,782: training iter 113, loss=0.6700360774993896 (13.511765s)
INFO:niftynet:2019-02-11 15:04:22,867: training iter 114, loss=0.739249587059021 (3.084869s)
INFO:niftynet:2019-02-11 15:04:27,498: training iter 115, loss=0.6396060585975647 (4.629361s)
INFO:niftynet:2019-02-11 15:04:28,789: training iter 116, loss=0.5911123752593994 (1.288964s)
INFO:niftynet:2019-02-11 15:04:41,127: training iter 117, loss=0.7674158811569214 (12.337872s)
INFO:niftynet:2019-02-11 15:04:44,141: training iter 118, loss=0.7239105701446533 (3.013251s)
INFO:niftynet:2019-02-11 15:04:45,346: training iter 119, loss=0.5799489617347717 (1.204642s)
INFO:niftynet:2019-02-11 15:04:55,020: training iter 120, loss=0.6456984281539917 (9.673281s)
INFO:niftynet:2019-02-11 15:04:55,937:     validation iter 120, loss=0.6988961696624756 (0.915067s)
INFO:niftynet:2019-02-11 15:05:01,337: training iter 121, loss=0.6396220326423645 (5.398166s)
INFO:niftynet:2019-02-11 15:05:02,542: training iter 122, loss=0.6106188297271729 (1.204452s)
INFO:niftynet:2019-02-11 15:05:08,055: training iter 123, loss=0.542340874671936 (5.512641s)
INFO:niftynet:2019-02-11 15:05:17,119: training iter 124, loss=0.7423973083496094 (9.063674s)
INFO:niftynet:2019-02-11 15:05:25,032: iter 125 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:05:25,033: training iter 125, loss=0.6568070650100708 (6.786368s)
INFO:niftynet:2019-02-11 15:05:26,317: training iter 126, loss=0.49624502658843994 (1.283478s)
INFO:niftynet:2019-02-11 15:05:30,869: training iter 127, loss=0.574698805809021 (4.551600s)
INFO:niftynet:2019-02-11 15:05:39,146: training iter 128, loss=0.617231011390686 (8.276997s)
INFO:niftynet:2019-02-11 15:05:40,493: training iter 129, loss=0.7418791055679321 (1.346723s)
INFO:niftynet:2019-02-11 15:05:44,779: training iter 130, loss=0.574752688407898 (4.284914s)
INFO:niftynet:2019-02-11 15:05:45,647:     validation iter 130, loss=0.6334668397903442 (0.864546s)
INFO:niftynet:2019-02-11 15:05:54,609: training iter 131, loss=0.6517462134361267 (8.959773s)
INFO:niftynet:2019-02-11 15:05:59,528: training iter 132, loss=0.712800145149231 (4.918932s)
INFO:niftynet:2019-02-11 15:06:00,626: training iter 133, loss=0.5169134140014648 (1.097311s)
INFO:niftynet:2019-02-11 15:06:05,798: training iter 134, loss=0.6143642067909241 (5.171499s)
INFO:niftynet:2019-02-11 15:06:16,757: training iter 135, loss=0.6257323026657104 (10.958919s)
INFO:niftynet:2019-02-11 15:06:18,635: training iter 136, loss=0.6413568258285522 (1.875429s)
INFO:niftynet:2019-02-11 15:06:23,209: training iter 137, loss=0.5905670523643494 (4.573438s)
INFO:niftynet:2019-02-11 15:06:24,389: training iter 138, loss=0.6392879486083984 (1.179744s)
INFO:niftynet:2019-02-11 15:06:36,497: training iter 139, loss=0.6067596077919006 (12.108674s)
INFO:niftynet:2019-02-11 15:06:42,646: training iter 140, loss=0.6186060905456543 (6.146997s)
INFO:niftynet:2019-02-11 15:06:43,746:     validation iter 140, loss=0.6189655661582947 (1.095801s)
INFO:niftynet:2019-02-11 15:06:44,862: training iter 141, loss=0.6491420269012451 (1.115770s)
INFO:niftynet:2019-02-11 15:06:48,457: training iter 142, loss=0.7515873312950134 (3.594169s)
INFO:niftynet:2019-02-11 15:07:01,778: training iter 143, loss=0.6183459758758545 (13.315163s)
INFO:niftynet:2019-02-11 15:07:06,746: training iter 144, loss=0.6650512218475342 (4.968261s)
INFO:niftynet:2019-02-11 15:07:07,934: training iter 145, loss=0.731020450592041 (1.187128s)
INFO:niftynet:2019-02-11 15:07:09,473: training iter 146, loss=0.5030404925346375 (1.538586s)
INFO:niftynet:2019-02-11 15:07:24,001: training iter 147, loss=0.7653862237930298 (14.527356s)
INFO:niftynet:2019-02-11 15:07:29,557: training iter 148, loss=0.6451079249382019 (5.554915s)
INFO:niftynet:2019-02-11 15:07:30,826: training iter 149, loss=0.5301671028137207 (1.268032s)
INFO:niftynet:2019-02-11 15:07:34,021: iter 150 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:07:34,022: training iter 150, loss=0.7102226614952087 (1.597999s)
INFO:niftynet:2019-02-11 15:07:34,957:     validation iter 150, loss=0.7218567132949829 (0.934594s)
INFO:niftynet:2019-02-11 15:07:43,276: training iter 151, loss=0.6679437160491943 (8.315700s)
INFO:niftynet:2019-02-11 15:07:44,333: training iter 152, loss=0.7599645853042603 (1.056099s)
INFO:niftynet:2019-02-11 15:07:50,475: training iter 153, loss=0.7708832025527954 (6.141528s)
INFO:niftynet:2019-02-11 15:07:52,005: training iter 154, loss=0.502004861831665 (1.529104s)
INFO:niftynet:2019-02-11 15:07:59,422: training iter 155, loss=0.6525698304176331 (7.415297s)
INFO:niftynet:2019-02-11 15:08:05,912: training iter 156, loss=0.6608991622924805 (6.487726s)
INFO:niftynet:2019-02-11 15:08:12,252: training iter 157, loss=0.501152753829956 (6.340356s)
INFO:niftynet:2019-02-11 15:08:13,532: training iter 158, loss=0.6753659248352051 (1.279540s)
INFO:niftynet:2019-02-11 15:08:24,221: training iter 159, loss=0.5475775599479675 (10.688159s)
INFO:niftynet:2019-02-11 15:08:26,374: training iter 160, loss=0.5503107309341431 (2.151806s)
INFO:niftynet:2019-02-11 15:08:27,364:     validation iter 160, loss=0.5446860790252686 (0.988974s)
INFO:niftynet:2019-02-11 15:08:30,554: training iter 161, loss=0.6808087825775146 (3.187432s)
INFO:niftynet:2019-02-11 15:08:36,328: training iter 162, loss=0.6676888465881348 (5.772692s)
INFO:niftynet:2019-02-11 15:08:48,530: training iter 163, loss=0.7416593432426453 (12.202282s)
INFO:niftynet:2019-02-11 15:08:50,929: training iter 164, loss=0.593779981136322 (2.398761s)
INFO:niftynet:2019-02-11 15:08:52,226: training iter 165, loss=0.5800051689147949 (1.294084s)
INFO:niftynet:2019-02-11 15:08:59,614: training iter 166, loss=0.5867613554000854 (7.387725s)
INFO:niftynet:2019-02-11 15:09:08,300: training iter 167, loss=0.6277493238449097 (8.685916s)
INFO:niftynet:2019-02-11 15:09:14,170: training iter 168, loss=0.6635016202926636 (5.869897s)
INFO:niftynet:2019-02-11 15:09:15,430: training iter 169, loss=0.6776192784309387 (1.259098s)
INFO:niftynet:2019-02-11 15:09:19,780: training iter 170, loss=0.5873281955718994 (4.348304s)
INFO:niftynet:2019-02-11 15:09:20,952:     validation iter 170, loss=0.5728654861450195 (1.168077s)
INFO:niftynet:2019-02-11 15:09:29,281: training iter 171, loss=0.7326300144195557 (8.327662s)
INFO:niftynet:2019-02-11 15:09:35,064: training iter 172, loss=0.7065942287445068 (5.782492s)
INFO:niftynet:2019-02-11 15:09:38,677: training iter 173, loss=0.6284042596817017 (3.612663s)
INFO:niftynet:2019-02-11 15:09:41,490: training iter 174, loss=0.4987301230430603 (2.812793s)
INFO:niftynet:2019-02-11 15:09:51,760: iter 175 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:09:51,761: training iter 175, loss=0.51985764503479 (9.258270s)
INFO:niftynet:2019-02-11 15:09:58,143: training iter 176, loss=0.6261329650878906 (6.381707s)
INFO:niftynet:2019-02-11 15:10:03,687: training iter 177, loss=0.7644822001457214 (5.543923s)
INFO:niftynet:2019-02-11 15:10:05,157: training iter 178, loss=0.5911495685577393 (1.468812s)
INFO:niftynet:2019-02-11 15:10:08,248: training iter 179, loss=0.7226569652557373 (3.090598s)
INFO:niftynet:2019-02-11 15:10:15,695: training iter 180, loss=0.7689591646194458 (7.446316s)
INFO:niftynet:2019-02-11 15:10:17,093:     validation iter 180, loss=0.7210275530815125 (1.395654s)
INFO:niftynet:2019-02-11 15:10:23,725: training iter 181, loss=0.6828904151916504 (6.631020s)
INFO:niftynet:2019-02-11 15:10:28,137: training iter 182, loss=0.6062191724777222 (4.411101s)
INFO:niftynet:2019-02-11 15:10:29,533: training iter 183, loss=0.5132049918174744 (1.395548s)
INFO:niftynet:2019-02-11 15:10:36,519: training iter 184, loss=0.7249128818511963 (6.984327s)
INFO:niftynet:2019-02-11 15:10:45,111: training iter 185, loss=0.6093683242797852 (8.589484s)
INFO:niftynet:2019-02-11 15:10:46,847: training iter 186, loss=0.7694845199584961 (1.734882s)
INFO:niftynet:2019-02-11 15:10:49,867: training iter 187, loss=0.7061182260513306 (3.019587s)
INFO:niftynet:2019-02-11 15:10:57,418: training iter 188, loss=0.7696300745010376 (7.549776s)
INFO:niftynet:2019-02-11 15:11:02,669: training iter 189, loss=0.6493343114852905 (5.251050s)
INFO:niftynet:2019-02-11 15:11:09,214: training iter 190, loss=0.6356600522994995 (6.543569s)
INFO:niftynet:2019-02-11 15:11:10,483:     validation iter 190, loss=0.6036076545715332 (1.267090s)
INFO:niftynet:2019-02-11 15:11:15,699: training iter 191, loss=0.6193403005599976 (5.215428s)
INFO:niftynet:2019-02-11 15:11:20,937: training iter 192, loss=0.7167419195175171 (5.237185s)
INFO:niftynet:2019-02-11 15:11:27,073: training iter 193, loss=0.7047837376594543 (6.134759s)
INFO:niftynet:2019-02-11 15:11:31,326: training iter 194, loss=0.585974395275116 (4.252726s)
INFO:niftynet:2019-02-11 15:11:38,615: training iter 195, loss=0.7405593991279602 (7.288865s)
INFO:niftynet:2019-02-11 15:11:40,757: training iter 196, loss=0.5811727643013 (2.141604s)
INFO:niftynet:2019-02-11 15:11:49,243: training iter 197, loss=0.520691990852356 (8.485064s)
INFO:niftynet:2019-02-11 15:11:50,382: training iter 198, loss=0.639972448348999 (1.138711s)
INFO:niftynet:2019-02-11 15:11:56,368: training iter 199, loss=0.5548005104064941 (5.986136s)
INFO:niftynet:2019-02-11 15:12:02,370: iter 200 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:12:02,370: training iter 200, loss=0.6470983028411865 (4.853643s)
INFO:niftynet:2019-02-11 15:12:03,423:     validation iter 200, loss=0.6645491719245911 (1.051504s)
INFO:niftynet:2019-02-11 15:12:12,311: training iter 201, loss=0.5820770263671875 (8.886179s)
INFO:niftynet:2019-02-11 15:12:13,546: training iter 202, loss=0.6356555223464966 (1.234902s)
INFO:niftynet:2019-02-11 15:12:16,951: training iter 203, loss=0.6228046417236328 (3.404919s)
INFO:niftynet:2019-02-11 15:12:20,012: training iter 204, loss=0.6322258710861206 (3.060270s)
INFO:niftynet:2019-02-11 15:12:34,028: training iter 205, loss=0.6760894060134888 (14.015088s)
INFO:niftynet:2019-02-11 15:12:35,045: training iter 206, loss=0.698733925819397 (1.013471s)
INFO:niftynet:2019-02-11 15:12:38,499: training iter 207, loss=0.6095907688140869 (3.454478s)
INFO:niftynet:2019-02-11 15:12:39,371: training iter 208, loss=0.6882809996604919 (0.871280s)
INFO:niftynet:2019-02-11 15:12:48,439: training iter 209, loss=0.6624111533164978 (9.067712s)
INFO:niftynet:2019-02-11 15:13:12,558: training iter 210, loss=0.5982749462127686 (24.117733s)
INFO:niftynet:2019-02-11 15:13:13,596:     validation iter 210, loss=0.7584089040756226 (1.035737s)
INFO:niftynet:2019-02-11 15:13:14,751: training iter 211, loss=0.6777820587158203 (1.154014s)
INFO:niftynet:2019-02-11 15:13:16,270: training iter 212, loss=0.6760294437408447 (1.518311s)
INFO:niftynet:2019-02-11 15:13:17,508: training iter 213, loss=0.6003006100654602 (1.238039s)
INFO:niftynet:2019-02-11 15:13:31,725: training iter 214, loss=0.5786746740341187 (14.216324s)
INFO:niftynet:2019-02-11 15:13:39,825: training iter 215, loss=0.5766804218292236 (8.098647s)
INFO:niftynet:2019-02-11 15:13:40,952: training iter 216, loss=0.5948030948638916 (1.125362s)
INFO:niftynet:2019-02-11 15:13:42,493: training iter 217, loss=0.5716050863265991 (1.540255s)
INFO:niftynet:2019-02-11 15:13:54,210: training iter 218, loss=0.508400022983551 (11.717024s)
INFO:niftynet:2019-02-11 15:13:55,388: training iter 219, loss=0.6717804074287415 (1.177143s)
INFO:niftynet:2019-02-11 15:14:01,484: training iter 220, loss=0.5189239978790283 (6.095042s)
INFO:niftynet:2019-02-11 15:14:02,523:     validation iter 220, loss=0.6048750877380371 (1.037320s)
INFO:niftynet:2019-02-11 15:14:03,848: training iter 221, loss=0.7233467698097229 (1.323595s)
INFO:niftynet:2019-02-11 15:14:16,953: training iter 222, loss=0.6857740879058838 (13.104703s)
INFO:niftynet:2019-02-11 15:14:18,146: training iter 223, loss=0.6770662069320679 (1.193173s)
INFO:niftynet:2019-02-11 15:14:20,402: training iter 224, loss=0.7030922174453735 (2.254242s)
INFO:niftynet:2019-02-11 15:14:22,637: iter 225 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:14:22,643: training iter 225, loss=0.6384694576263428 (1.243158s)
INFO:niftynet:2019-02-11 15:14:33,458: training iter 226, loss=0.7647140026092529 (10.815003s)
INFO:niftynet:2019-02-11 15:14:44,616: training iter 227, loss=0.7740530967712402 (11.158367s)
INFO:niftynet:2019-02-11 15:14:45,808: training iter 228, loss=0.5539867877960205 (1.191041s)
INFO:niftynet:2019-02-11 15:14:47,187: training iter 229, loss=0.7366291284561157 (1.378678s)
INFO:niftynet:2019-02-11 15:14:58,829: training iter 230, loss=0.7627939581871033 (11.641008s)
INFO:niftynet:2019-02-11 15:15:07,881:     validation iter 230, loss=0.7146644592285156 (9.050548s)
INFO:niftynet:2019-02-11 15:15:09,009: training iter 231, loss=0.7374937534332275 (1.126340s)
INFO:niftynet:2019-02-11 15:15:10,235: training iter 232, loss=0.5754870176315308 (1.225603s)
INFO:niftynet:2019-02-11 15:15:14,037: training iter 233, loss=0.65907883644104 (3.800303s)
INFO:niftynet:2019-02-11 15:15:17,662: training iter 234, loss=0.5290757417678833 (3.625482s)
INFO:niftynet:2019-02-11 15:15:26,045: training iter 235, loss=0.6113746762275696 (8.381732s)
INFO:niftynet:2019-02-11 15:15:32,497: training iter 236, loss=0.701629102230072 (6.451214s)
INFO:niftynet:2019-02-11 15:15:33,509: training iter 237, loss=0.6110721826553345 (1.011184s)
INFO:niftynet:2019-02-11 15:15:40,192: training iter 238, loss=0.6427414417266846 (6.682152s)
INFO:niftynet:2019-02-11 15:15:47,252: training iter 239, loss=0.5524479150772095 (7.060018s)
INFO:niftynet:2019-02-11 15:15:50,092: training iter 240, loss=0.6145340204238892 (2.838960s)
INFO:niftynet:2019-02-11 15:15:51,182:     validation iter 240, loss=0.693987250328064 (1.087581s)
INFO:niftynet:2019-02-11 15:15:55,075: training iter 241, loss=0.553502082824707 (3.886430s)
INFO:niftynet:2019-02-11 15:15:59,756: training iter 242, loss=0.5900784134864807 (4.680489s)
INFO:niftynet:2019-02-11 15:16:08,747: training iter 243, loss=0.516313910484314 (8.990346s)
INFO:niftynet:2019-02-11 15:16:17,470: training iter 244, loss=0.6499454975128174 (8.722793s)
INFO:niftynet:2019-02-11 15:16:19,316: training iter 245, loss=0.7557029724121094 (1.844736s)
INFO:niftynet:2019-02-11 15:16:22,084: training iter 246, loss=0.7661420106887817 (2.766669s)
INFO:niftynet:2019-02-11 15:16:29,011: training iter 247, loss=0.6835464239120483 (6.927093s)
INFO:niftynet:2019-02-11 15:16:30,298: training iter 248, loss=0.6654156446456909 (1.286613s)
INFO:niftynet:2019-02-11 15:16:40,294: training iter 249, loss=0.6706843376159668 (9.995496s)
INFO:niftynet:2019-02-11 15:16:43,826: iter 250 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:16:43,826: training iter 250, loss=0.5949090123176575 (2.248788s)
INFO:niftynet:2019-02-11 15:16:44,955:     validation iter 250, loss=0.6470624804496765 (1.127466s)
INFO:niftynet:2019-02-11 15:16:48,926: training iter 251, loss=0.5823090076446533 (3.969260s)
INFO:niftynet:2019-02-11 15:16:54,057: training iter 252, loss=0.6662178039550781 (5.129470s)
INFO:niftynet:2019-02-11 15:17:03,725: training iter 253, loss=0.6955201029777527 (9.664587s)
INFO:niftynet:2019-02-11 15:17:04,739: training iter 254, loss=0.6654410362243652 (1.014004s)
INFO:niftynet:2019-02-11 15:17:11,598: training iter 255, loss=0.6921744346618652 (6.857861s)
INFO:niftynet:2019-02-11 15:17:15,583: training iter 256, loss=0.7153205275535583 (3.982841s)
INFO:niftynet:2019-02-11 15:17:22,496: training iter 257, loss=0.601832926273346 (6.912379s)
INFO:niftynet:2019-02-11 15:17:26,390: training iter 258, loss=0.504928469657898 (3.893246s)
INFO:niftynet:2019-02-11 15:17:31,543: training iter 259, loss=0.6954302787780762 (5.152868s)
INFO:niftynet:2019-02-11 15:17:37,249: training iter 260, loss=0.6885049939155579 (5.704989s)
INFO:niftynet:2019-02-11 15:17:38,442:     validation iter 260, loss=0.5821616649627686 (1.183367s)
INFO:niftynet:2019-02-11 15:17:44,077: training iter 261, loss=0.6104521155357361 (5.631853s)
INFO:niftynet:2019-02-11 15:17:46,813: training iter 262, loss=0.6402517557144165 (2.736621s)
INFO:niftynet:2019-02-11 15:17:55,713: training iter 263, loss=0.5569010972976685 (8.896124s)
INFO:niftynet:2019-02-11 15:17:59,803: training iter 264, loss=0.7269202470779419 (4.089868s)
INFO:niftynet:2019-02-11 15:18:03,979: training iter 265, loss=0.7421488165855408 (4.174642s)
INFO:niftynet:2019-02-11 15:18:06,743: training iter 266, loss=0.6063544750213623 (2.762126s)
INFO:niftynet:2019-02-11 15:18:17,744: training iter 267, loss=0.6836779117584229 (10.997346s)
INFO:niftynet:2019-02-11 15:18:23,148: training iter 268, loss=0.552819013595581 (5.403188s)
INFO:niftynet:2019-02-11 15:18:24,472: training iter 269, loss=0.6739885807037354 (1.323032s)
INFO:niftynet:2019-02-11 15:18:29,668: training iter 270, loss=0.5399994850158691 (5.194906s)
INFO:niftynet:2019-02-11 15:18:30,948:     validation iter 270, loss=0.5772250890731812 (1.277523s)
INFO:niftynet:2019-02-11 15:18:39,332: training iter 271, loss=0.5602251887321472 (8.380776s)
INFO:niftynet:2019-02-11 15:18:43,041: training iter 272, loss=0.6342149972915649 (3.708727s)
INFO:niftynet:2019-02-11 15:18:49,526: training iter 273, loss=0.5198254585266113 (6.484189s)
INFO:niftynet:2019-02-11 15:18:51,800: training iter 274, loss=0.6386606693267822 (2.273677s)
INFO:niftynet:2019-02-11 15:18:58,236: iter 275 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:18:58,237: training iter 275, loss=0.6825046539306641 (5.193164s)
INFO:niftynet:2019-02-11 15:19:03,438: training iter 276, loss=0.5737361907958984 (5.201209s)
INFO:niftynet:2019-02-11 15:19:11,913: training iter 277, loss=0.6890250444412231 (8.474011s)
INFO:niftynet:2019-02-11 15:19:13,142: training iter 278, loss=0.49526143074035645 (1.228728s)
INFO:niftynet:2019-02-11 15:19:20,281: training iter 279, loss=0.6140892505645752 (7.137778s)
INFO:niftynet:2019-02-11 15:19:23,406: training iter 280, loss=0.6438642144203186 (3.123236s)
INFO:niftynet:2019-02-11 15:19:24,422:     validation iter 280, loss=0.5458619594573975 (1.014616s)
INFO:niftynet:2019-02-11 15:19:31,269: training iter 281, loss=0.49878522753715515 (6.847276s)
INFO:niftynet:2019-02-11 15:19:36,602: training iter 282, loss=0.6042845845222473 (5.330877s)
INFO:niftynet:2019-02-11 15:19:37,776: training iter 283, loss=0.5704559087753296 (1.173231s)
INFO:niftynet:2019-02-11 15:19:47,499: training iter 284, loss=0.6042461395263672 (9.722514s)
INFO:niftynet:2019-02-11 15:19:52,525: training iter 285, loss=0.6753785014152527 (5.024832s)
INFO:niftynet:2019-02-11 15:19:59,135: training iter 286, loss=0.6768904328346252 (6.608389s)
INFO:niftynet:2019-02-11 15:20:01,051: training iter 287, loss=0.7116904258728027 (1.915843s)
INFO:niftynet:2019-02-11 15:20:10,575: training iter 288, loss=0.6814053058624268 (9.522882s)
INFO:niftynet:2019-02-11 15:20:13,705: training iter 289, loss=0.651689350605011 (3.128990s)
INFO:niftynet:2019-02-11 15:20:14,967: training iter 290, loss=0.6551430225372314 (1.261393s)
INFO:niftynet:2019-02-11 15:20:15,922:     validation iter 290, loss=0.6962092518806458 (0.952050s)
INFO:niftynet:2019-02-11 15:20:25,544: training iter 291, loss=0.5810105800628662 (9.621736s)
INFO:niftynet:2019-02-11 15:20:28,228: training iter 292, loss=0.649256706237793 (2.683639s)
INFO:niftynet:2019-02-11 15:20:36,786: training iter 293, loss=0.6310430765151978 (8.557423s)
INFO:niftynet:2019-02-11 15:20:38,865: training iter 294, loss=0.7092082500457764 (2.079086s)
INFO:niftynet:2019-02-11 15:20:46,265: training iter 295, loss=0.5581894516944885 (7.398504s)
INFO:niftynet:2019-02-11 15:20:50,813: training iter 296, loss=0.7636879086494446 (4.546256s)
INFO:niftynet:2019-02-11 15:20:59,066: training iter 297, loss=0.6991419792175293 (8.252974s)
INFO:niftynet:2019-02-11 15:21:00,280: training iter 298, loss=0.6469417810440063 (1.213514s)
INFO:niftynet:2019-02-11 15:21:07,605: training iter 299, loss=0.5404341816902161 (7.324872s)
INFO:niftynet:2019-02-11 15:21:10,463: iter 300 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:21:10,465: training iter 300, loss=0.5503780841827393 (1.385569s)
INFO:niftynet:2019-02-11 15:21:11,625:     validation iter 300, loss=0.513087272644043 (1.157541s)
INFO:niftynet:2019-02-11 15:21:18,970: training iter 301, loss=0.7688466310501099 (7.343512s)
INFO:niftynet:2019-02-11 15:21:23,033: training iter 302, loss=0.6506770849227905 (4.063028s)
INFO:niftynet:2019-02-11 15:21:25,762: training iter 303, loss=0.6647394895553589 (2.728720s)
INFO:niftynet:2019-02-11 15:21:35,257: training iter 304, loss=0.6440190076828003 (9.494280s)
INFO:niftynet:2019-02-11 15:21:37,296: training iter 305, loss=0.6186400651931763 (2.037610s)
INFO:niftynet:2019-02-11 15:21:43,191: training iter 306, loss=0.501828670501709 (5.894456s)
INFO:niftynet:2019-02-11 15:21:44,250: training iter 307, loss=0.6095002889633179 (1.059338s)
INFO:niftynet:2019-02-11 15:21:54,798: training iter 308, loss=0.7074375152587891 (10.547448s)
INFO:niftynet:2019-02-11 15:21:57,567: training iter 309, loss=0.6198904514312744 (2.768151s)
INFO:niftynet:2019-02-11 15:21:58,824: training iter 310, loss=0.5113090872764587 (1.256629s)
INFO:niftynet:2019-02-11 15:21:59,992:     validation iter 310, loss=0.5308811664581299 (1.162314s)
INFO:niftynet:2019-02-11 15:22:09,905: training iter 311, loss=0.7311729192733765 (9.908853s)
INFO:niftynet:2019-02-11 15:22:13,920: training iter 312, loss=0.6599447727203369 (4.014583s)
INFO:niftynet:2019-02-11 15:22:22,107: training iter 313, loss=0.7585000395774841 (8.186075s)
INFO:niftynet:2019-02-11 15:22:23,391: training iter 314, loss=0.7483932375907898 (1.283234s)
INFO:niftynet:2019-02-11 15:22:26,877: training iter 315, loss=0.6523558497428894 (3.469861s)
INFO:niftynet:2019-02-11 15:22:33,814: training iter 316, loss=0.5681756138801575 (6.935246s)
INFO:niftynet:2019-02-11 15:22:41,771: training iter 317, loss=0.6671212911605835 (7.956696s)
INFO:niftynet:2019-02-11 15:22:43,527: training iter 318, loss=0.6766873598098755 (1.755470s)
INFO:niftynet:2019-02-11 15:22:47,964: training iter 319, loss=0.6824537515640259 (4.436386s)
INFO:niftynet:2019-02-11 15:22:56,428: training iter 320, loss=0.6231628656387329 (8.463517s)
INFO:niftynet:2019-02-11 15:22:57,647:     validation iter 320, loss=0.6019700765609741 (1.215572s)
INFO:niftynet:2019-02-11 15:23:04,478: training iter 321, loss=0.5160907506942749 (6.828824s)
INFO:niftynet:2019-02-11 15:23:05,391: training iter 322, loss=0.6077749729156494 (0.913361s)
INFO:niftynet:2019-02-11 15:23:06,974: training iter 323, loss=0.675055980682373 (1.582691s)
INFO:niftynet:2019-02-11 15:23:28,550: training iter 324, loss=0.620505690574646 (21.559604s)
INFO:niftynet:2019-02-11 15:23:33,005: iter 325 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:23:33,006: training iter 325, loss=0.62757807970047 (3.208220s)
INFO:niftynet:2019-02-11 15:23:34,666: training iter 326, loss=0.6608989238739014 (1.659180s)
INFO:niftynet:2019-02-11 15:23:36,042: training iter 327, loss=0.5562368631362915 (1.371938s)
INFO:niftynet:2019-02-11 15:23:47,469: training iter 328, loss=0.7183750867843628 (11.410262s)
INFO:niftynet:2019-02-11 15:23:49,998: training iter 329, loss=0.423920214176178 (2.528342s)
INFO:niftynet:2019-02-11 15:23:53,256: training iter 330, loss=0.6360591053962708 (3.256886s)
INFO:niftynet:2019-02-11 15:23:54,642:     validation iter 330, loss=0.6050388813018799 (1.382163s)
INFO:niftynet:2019-02-11 15:23:56,240: training iter 331, loss=0.6429762840270996 (1.595730s)
INFO:niftynet:2019-02-11 15:24:12,788: training iter 332, loss=0.7172219753265381 (16.547729s)
INFO:niftynet:2019-02-11 15:24:13,824: training iter 333, loss=0.6239930391311646 (1.035326s)
INFO:niftynet:2019-02-11 15:24:17,775: training iter 334, loss=0.5941022634506226 (3.950422s)
INFO:niftynet:2019-02-11 15:24:20,122: training iter 335, loss=0.5283266305923462 (2.345705s)
INFO:niftynet:2019-02-11 15:24:30,323: training iter 336, loss=0.5607025027275085 (10.200561s)
INFO:niftynet:2019-02-11 15:24:33,405: training iter 337, loss=0.6129424571990967 (3.080861s)
INFO:niftynet:2019-02-11 15:24:36,267: training iter 338, loss=0.6665457487106323 (2.861197s)
INFO:niftynet:2019-02-11 15:24:40,318: training iter 339, loss=0.648405134677887 (4.049995s)
INFO:niftynet:2019-02-11 15:24:53,989: training iter 340, loss=0.5086888074874878 (13.669941s)
INFO:niftynet:2019-02-11 15:24:54,871:     validation iter 340, loss=0.5359618067741394 (0.880691s)
INFO:niftynet:2019-02-11 15:24:56,254: training iter 341, loss=0.6152279376983643 (1.381526s)
INFO:niftynet:2019-02-11 15:25:01,284: training iter 342, loss=0.5447447299957275 (5.017320s)
INFO:niftynet:2019-02-11 15:25:06,379: training iter 343, loss=0.6442275047302246 (5.094226s)
INFO:niftynet:2019-02-11 15:25:16,208: training iter 344, loss=0.4770883321762085 (9.828133s)
INFO:niftynet:2019-02-11 15:25:18,496: training iter 345, loss=0.7478995323181152 (2.281688s)
INFO:niftynet:2019-02-11 15:25:20,765: training iter 346, loss=0.7480567097663879 (2.264994s)
INFO:niftynet:2019-02-11 15:25:25,149: training iter 347, loss=0.6104774475097656 (4.383846s)
INFO:niftynet:2019-02-11 15:25:31,692: training iter 348, loss=0.5476528406143188 (6.542348s)
INFO:niftynet:2019-02-11 15:25:39,904: training iter 349, loss=0.6757029294967651 (8.212360s)
INFO:niftynet:2019-02-11 15:25:43,618: iter 350 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:25:43,619: training iter 350, loss=0.7651832103729248 (2.454340s)
INFO:niftynet:2019-02-11 15:25:44,729:     validation iter 350, loss=0.625198483467102 (1.109177s)
INFO:niftynet:2019-02-11 15:25:47,044: training iter 351, loss=0.6156756281852722 (2.313959s)
INFO:niftynet:2019-02-11 15:25:56,982: training iter 352, loss=0.526964545249939 (9.938370s)
INFO:niftynet:2019-02-11 15:26:02,655: training iter 353, loss=0.5346689224243164 (5.671918s)
INFO:niftynet:2019-02-11 15:26:04,692: training iter 354, loss=0.5770898461341858 (2.036794s)
INFO:niftynet:2019-02-11 15:26:07,378: training iter 355, loss=0.6451703310012817 (2.685550s)
INFO:niftynet:2019-02-11 15:26:14,945: training iter 356, loss=0.7675219774246216 (7.565187s)
INFO:niftynet:2019-02-11 15:26:22,206: training iter 357, loss=0.5616837739944458 (7.260648s)
INFO:niftynet:2019-02-11 15:26:29,396: training iter 358, loss=0.4560879170894623 (7.189083s)
INFO:niftynet:2019-02-11 15:26:30,720: training iter 359, loss=0.6265087127685547 (1.322455s)
INFO:niftynet:2019-02-11 15:26:37,795: training iter 360, loss=0.586172878742218 (7.074593s)
INFO:niftynet:2019-02-11 15:26:39,056:     validation iter 360, loss=0.6031970977783203 (1.249280s)
INFO:niftynet:2019-02-11 15:26:48,512: training iter 361, loss=0.7415838241577148 (9.453885s)
INFO:niftynet:2019-02-11 15:26:49,571: training iter 362, loss=0.6866227984428406 (1.058563s)
INFO:niftynet:2019-02-11 15:26:50,692: training iter 363, loss=0.7278017997741699 (1.121485s)
INFO:niftynet:2019-02-11 15:26:57,209: training iter 364, loss=0.6633970141410828 (6.516665s)
INFO:niftynet:2019-02-11 15:27:09,496: training iter 365, loss=0.499767005443573 (12.285682s)
INFO:niftynet:2019-02-11 15:27:10,737: training iter 366, loss=0.7344688773155212 (1.239074s)
INFO:niftynet:2019-02-11 15:27:12,135: training iter 367, loss=0.7629712820053101 (1.398183s)
INFO:niftynet:2019-02-11 15:27:15,894: training iter 368, loss=0.5439141988754272 (3.758100s)
INFO:niftynet:2019-02-11 15:27:31,675: training iter 369, loss=0.6534796953201294 (15.781062s)
INFO:niftynet:2019-02-11 15:27:32,884: training iter 370, loss=0.6205481886863708 (1.207428s)
INFO:niftynet:2019-02-11 15:27:33,991:     validation iter 370, loss=0.5897173881530762 (1.105860s)
INFO:niftynet:2019-02-11 15:27:35,312: training iter 371, loss=0.7361345887184143 (1.315366s)
INFO:niftynet:2019-02-11 15:27:36,828: training iter 372, loss=0.6313270926475525 (1.515261s)
INFO:niftynet:2019-02-11 15:27:49,433: training iter 373, loss=0.659407377243042 (12.605214s)
INFO:niftynet:2019-02-11 15:27:52,777: training iter 374, loss=0.643993079662323 (3.343126s)
INFO:niftynet:2019-02-11 15:27:57,052: iter 375 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:27:57,053: training iter 375, loss=0.6689977645874023 (3.035818s)
INFO:niftynet:2019-02-11 15:27:58,180: training iter 376, loss=0.7282078862190247 (1.127279s)
INFO:niftynet:2019-02-11 15:28:09,654: training iter 377, loss=0.615950345993042 (11.473408s)
INFO:niftynet:2019-02-11 15:28:13,918: training iter 378, loss=0.6052178144454956 (4.263273s)
INFO:niftynet:2019-02-11 15:28:20,557: training iter 379, loss=0.6872616410255432 (6.638907s)
INFO:niftynet:2019-02-11 15:28:21,772: training iter 380, loss=0.6667304039001465 (1.212705s)
INFO:niftynet:2019-02-11 15:28:33,075:     validation iter 380, loss=0.6150340437889099 (11.301403s)
INFO:niftynet:2019-02-11 15:28:39,116: training iter 381, loss=0.5820514559745789 (6.038650s)
INFO:niftynet:2019-02-11 15:28:41,404: training iter 382, loss=0.634658932685852 (2.287344s)
INFO:niftynet:2019-02-11 15:28:42,613: training iter 383, loss=0.5685751438140869 (1.209310s)
INFO:niftynet:2019-02-11 15:28:50,054: training iter 384, loss=0.597470760345459 (7.441007s)
INFO:niftynet:2019-02-11 15:28:56,574: training iter 385, loss=0.615709125995636 (6.506374s)
INFO:niftynet:2019-02-11 15:29:02,122: training iter 386, loss=0.6499561071395874 (5.547824s)
INFO:niftynet:2019-02-11 15:29:03,164: training iter 387, loss=0.5956389307975769 (1.042259s)
INFO:niftynet:2019-02-11 15:29:09,215: training iter 388, loss=0.5132200717926025 (6.049849s)
INFO:niftynet:2019-02-11 15:29:12,118: training iter 389, loss=0.5589927434921265 (2.903532s)
INFO:niftynet:2019-02-11 15:29:27,271: training iter 390, loss=0.5963805913925171 (15.123564s)
INFO:niftynet:2019-02-11 15:29:28,388:     validation iter 390, loss=0.5639306902885437 (1.114148s)
INFO:niftynet:2019-02-11 15:29:29,717: training iter 391, loss=0.6478384733200073 (1.326121s)
INFO:niftynet:2019-02-11 15:29:35,248: training iter 392, loss=0.6148561239242554 (5.529873s)
INFO:niftynet:2019-02-11 15:29:36,478: training iter 393, loss=0.6836217641830444 (1.230552s)
INFO:niftynet:2019-02-11 15:29:46,145: training iter 394, loss=0.6601501703262329 (9.665687s)
INFO:niftynet:2019-02-11 15:29:48,438: training iter 395, loss=0.5839777588844299 (2.291208s)
INFO:niftynet:2019-02-11 15:29:59,108: training iter 396, loss=0.5356935262680054 (10.667758s)
INFO:niftynet:2019-02-11 15:30:02,868: training iter 397, loss=0.7093110084533691 (3.759889s)
INFO:niftynet:2019-02-11 15:30:06,767: training iter 398, loss=0.5792293548583984 (3.898303s)
INFO:niftynet:2019-02-11 15:30:11,596: training iter 399, loss=0.7640705108642578 (4.829368s)
INFO:niftynet:2019-02-11 15:30:22,659: iter 400 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:30:22,659: training iter 400, loss=0.6334617137908936 (9.798768s)
INFO:niftynet:2019-02-11 15:30:23,465:     validation iter 400, loss=0.489639014005661 (0.804354s)
INFO:niftynet:2019-02-11 15:30:24,844: training iter 401, loss=0.6570655703544617 (1.379424s)
INFO:niftynet:2019-02-11 15:30:26,200: training iter 402, loss=0.6609102487564087 (1.354825s)
INFO:niftynet:2019-02-11 15:30:27,562: training iter 403, loss=0.6971852779388428 (1.362550s)
INFO:niftynet:2019-02-11 15:30:48,006: training iter 404, loss=0.57773756980896 (20.419939s)
INFO:niftynet:2019-02-11 15:30:49,353: training iter 405, loss=0.5483683347702026 (1.344669s)
INFO:niftynet:2019-02-11 15:30:50,589: training iter 406, loss=0.6163304448127747 (1.233675s)
INFO:niftynet:2019-02-11 15:30:51,803: training iter 407, loss=0.4811934530735016 (1.212272s)
INFO:niftynet:2019-02-11 15:31:11,654: training iter 408, loss=0.5878674983978271 (19.850451s)
INFO:niftynet:2019-02-11 15:31:13,169: training iter 409, loss=0.6770421266555786 (1.513169s)
INFO:niftynet:2019-02-11 15:31:14,710: training iter 410, loss=0.5724623799324036 (1.539673s)
INFO:niftynet:2019-02-11 15:31:15,922:     validation iter 410, loss=0.6508091688156128 (1.199574s)
INFO:niftynet:2019-02-11 15:31:17,570: training iter 411, loss=0.6053354740142822 (1.645417s)
INFO:niftynet:2019-02-11 15:31:31,878: training iter 412, loss=0.6941875219345093 (14.307941s)
INFO:niftynet:2019-02-11 15:31:33,448: training iter 413, loss=0.662826657295227 (1.569733s)
INFO:niftynet:2019-02-11 15:31:36,000: training iter 414, loss=0.598581075668335 (2.550868s)
INFO:niftynet:2019-02-11 15:31:37,139: training iter 415, loss=0.5958687663078308 (1.137423s)
INFO:niftynet:2019-02-11 15:31:51,808: training iter 416, loss=0.5159505605697632 (14.667007s)
INFO:niftynet:2019-02-11 15:31:53,031: training iter 417, loss=0.45948076248168945 (1.220759s)
INFO:niftynet:2019-02-11 15:32:01,162: training iter 418, loss=0.48670026659965515 (8.131281s)
INFO:niftynet:2019-02-11 15:32:02,283: training iter 419, loss=0.4963533878326416 (1.120119s)
INFO:niftynet:2019-02-11 15:32:12,421: training iter 420, loss=0.7494776248931885 (10.136820s)
INFO:niftynet:2019-02-11 15:32:13,726:     validation iter 420, loss=0.7408435344696045 (1.301511s)
INFO:niftynet:2019-02-11 15:32:15,166: training iter 421, loss=0.6258794069290161 (1.428189s)
INFO:niftynet:2019-02-11 15:32:16,929: training iter 422, loss=0.6529005765914917 (1.762345s)
INFO:niftynet:2019-02-11 15:32:21,722: training iter 423, loss=0.5958337783813477 (4.793154s)
INFO:niftynet:2019-02-11 15:32:31,380: training iter 424, loss=0.5441893935203552 (9.657700s)
INFO:niftynet:2019-02-11 15:32:38,263: iter 425 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:32:38,263: training iter 425, loss=0.5067277550697327 (5.456258s)
INFO:niftynet:2019-02-11 15:32:40,412: training iter 426, loss=0.6239075064659119 (2.148795s)
INFO:niftynet:2019-02-11 15:32:44,569: training iter 427, loss=0.5968477129936218 (4.155879s)
INFO:niftynet:2019-02-11 15:32:50,686: training iter 428, loss=0.5066350698471069 (6.116655s)
INFO:niftynet:2019-02-11 15:32:58,758: training iter 429, loss=0.7403549551963806 (8.071762s)
INFO:niftynet:2019-02-11 15:33:00,609: training iter 430, loss=0.7275751829147339 (1.849300s)
INFO:niftynet:2019-02-11 15:33:01,734:     validation iter 430, loss=0.5168893933296204 (1.122195s)
INFO:niftynet:2019-02-11 15:33:07,585: training iter 431, loss=0.7077769637107849 (5.842657s)
INFO:niftynet:2019-02-11 15:33:08,589: training iter 432, loss=0.7684775590896606 (1.003181s)
INFO:niftynet:2019-02-11 15:33:18,312: training iter 433, loss=0.6211642622947693 (9.723527s)
INFO:niftynet:2019-02-11 15:33:24,365: training iter 434, loss=0.5946066975593567 (6.051841s)
INFO:niftynet:2019-02-11 15:33:25,400: training iter 435, loss=0.7125344276428223 (1.034474s)
INFO:niftynet:2019-02-11 15:33:26,408: training iter 436, loss=0.5902835130691528 (1.006142s)
INFO:niftynet:2019-02-11 15:33:53,157: training iter 437, loss=0.6579681038856506 (26.748637s)
INFO:niftynet:2019-02-11 15:33:54,362: training iter 438, loss=0.46725723147392273 (1.205006s)
INFO:niftynet:2019-02-11 15:33:55,850: training iter 439, loss=0.7017107605934143 (1.487239s)
INFO:niftynet:2019-02-11 15:33:57,497: training iter 440, loss=0.4828811287879944 (1.645012s)
INFO:niftynet:2019-02-11 15:33:58,747:     validation iter 440, loss=0.7655229568481445 (1.248653s)
INFO:niftynet:2019-02-11 15:34:13,775: training iter 441, loss=0.49901869893074036 (15.023969s)
INFO:niftynet:2019-02-11 15:34:17,159: training iter 442, loss=0.616504430770874 (3.382686s)
INFO:niftynet:2019-02-11 15:34:18,470: training iter 443, loss=0.5343286395072937 (1.311599s)
INFO:niftynet:2019-02-11 15:34:21,266: training iter 444, loss=0.6245714426040649 (2.795473s)
INFO:niftynet:2019-02-11 15:34:27,345: training iter 445, loss=0.7642641067504883 (6.076992s)
INFO:niftynet:2019-02-11 15:34:37,770: training iter 446, loss=0.5459417700767517 (10.422765s)
INFO:niftynet:2019-02-11 15:34:39,988: training iter 447, loss=0.6388528347015381 (2.218234s)
INFO:niftynet:2019-02-11 15:34:41,798: training iter 448, loss=0.5990052223205566 (1.807900s)
INFO:niftynet:2019-02-11 15:34:47,374: training iter 449, loss=0.7319278717041016 (5.576380s)
INFO:niftynet:2019-02-11 15:35:01,754: iter 450 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:35:01,754: training iter 450, loss=0.5641583204269409 (12.895060s)
INFO:niftynet:2019-02-11 15:35:02,858:     validation iter 450, loss=0.5743758678436279 (1.102546s)
INFO:niftynet:2019-02-11 15:35:04,187: training iter 451, loss=0.5191149711608887 (1.326752s)
INFO:niftynet:2019-02-11 15:35:06,110: training iter 452, loss=0.7640698552131653 (1.922256s)
INFO:niftynet:2019-02-11 15:35:07,551: training iter 453, loss=0.6642990708351135 (1.438860s)
INFO:niftynet:2019-02-11 15:35:20,787: training iter 454, loss=0.5695614814758301 (13.236230s)
INFO:niftynet:2019-02-11 15:35:23,283: training iter 455, loss=0.7582904100418091 (2.495419s)
INFO:niftynet:2019-02-11 15:35:24,464: training iter 456, loss=0.551846981048584 (1.178702s)
INFO:niftynet:2019-02-11 15:35:28,590: training iter 457, loss=0.6207010746002197 (4.125299s)
INFO:niftynet:2019-02-11 15:35:43,409: training iter 458, loss=0.5185049772262573 (14.818188s)
INFO:niftynet:2019-02-11 15:35:44,710: training iter 459, loss=0.6086164116859436 (1.300844s)
INFO:niftynet:2019-02-11 15:35:49,565: training iter 460, loss=0.5979428291320801 (4.853117s)
INFO:niftynet:2019-02-11 15:35:50,538:     validation iter 460, loss=0.6113952398300171 (0.970554s)
INFO:niftynet:2019-02-11 15:35:52,265: training iter 461, loss=0.7361221313476562 (1.725219s)
INFO:niftynet:2019-02-11 15:36:05,246: training iter 462, loss=0.620868444442749 (12.980363s)
INFO:niftynet:2019-02-11 15:36:08,681: training iter 463, loss=0.7545230388641357 (3.435333s)
INFO:niftynet:2019-02-11 15:36:09,838: training iter 464, loss=0.4820817708969116 (1.153200s)
INFO:niftynet:2019-02-11 15:36:11,087: training iter 465, loss=0.6402081251144409 (1.247014s)
INFO:niftynet:2019-02-11 15:36:25,735: training iter 466, loss=0.5506813526153564 (14.646272s)
INFO:niftynet:2019-02-11 15:36:26,953: training iter 467, loss=0.5918750762939453 (1.217723s)
INFO:niftynet:2019-02-11 15:36:30,014: training iter 468, loss=0.6951149702072144 (3.059943s)
INFO:niftynet:2019-02-11 15:36:31,292: training iter 469, loss=0.7672006487846375 (1.277612s)
INFO:niftynet:2019-02-11 15:36:46,424: training iter 470, loss=0.5825667381286621 (15.130513s)
INFO:niftynet:2019-02-11 15:36:47,531:     validation iter 470, loss=0.6945962309837341 (1.106436s)
INFO:niftynet:2019-02-11 15:36:48,847: training iter 471, loss=0.6643344759941101 (1.313973s)
INFO:niftynet:2019-02-11 15:36:53,060: training iter 472, loss=0.6006188988685608 (4.212411s)
INFO:niftynet:2019-02-11 15:36:54,205: training iter 473, loss=0.5918152332305908 (1.145140s)
INFO:niftynet:2019-02-11 15:37:05,796: training iter 474, loss=0.5701669454574585 (11.590572s)
INFO:niftynet:2019-02-11 15:37:16,151: iter 475 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:37:16,152: training iter 475, loss=0.6594387888908386 (8.906290s)
INFO:niftynet:2019-02-11 15:37:17,311: training iter 476, loss=0.7503315210342407 (1.158986s)
INFO:niftynet:2019-02-11 15:37:18,822: training iter 477, loss=0.69196617603302 (1.510931s)
INFO:niftynet:2019-02-11 15:37:25,350: training iter 478, loss=0.6576056480407715 (6.527564s)
INFO:niftynet:2019-02-11 15:37:28,602: training iter 479, loss=0.703342854976654 (3.251921s)
INFO:niftynet:2019-02-11 15:37:36,433: training iter 480, loss=0.574482798576355 (7.829695s)
INFO:niftynet:2019-02-11 15:37:37,516:     validation iter 480, loss=0.6335380673408508 (1.080100s)
INFO:niftynet:2019-02-11 15:37:42,377: training iter 481, loss=0.6058062314987183 (4.858327s)
INFO:niftynet:2019-02-11 15:37:49,431: training iter 482, loss=0.6625573635101318 (7.053127s)
INFO:niftynet:2019-02-11 15:37:54,900: training iter 483, loss=0.6867343187332153 (5.468174s)
INFO:niftynet:2019-02-11 15:37:56,266: training iter 484, loss=0.63761305809021 (1.365625s)
INFO:niftynet:2019-02-11 15:38:07,937: training iter 485, loss=0.5572528839111328 (11.670081s)
INFO:niftynet:2019-02-11 15:38:09,247: training iter 486, loss=0.5998638272285461 (1.307687s)
INFO:niftynet:2019-02-11 15:38:12,827: training iter 487, loss=0.6059762239456177 (3.579752s)
INFO:niftynet:2019-02-11 15:38:18,132: training iter 488, loss=0.591823935508728 (5.304681s)
INFO:niftynet:2019-02-11 15:38:26,658: training iter 489, loss=0.7130566835403442 (8.525150s)
INFO:niftynet:2019-02-11 15:38:28,317: training iter 490, loss=0.6395683288574219 (1.658347s)
INFO:niftynet:2019-02-11 15:38:29,234:     validation iter 490, loss=0.6163023710250854 (0.914231s)
INFO:niftynet:2019-02-11 15:38:34,350: training iter 491, loss=0.7058594226837158 (5.113814s)
INFO:niftynet:2019-02-11 15:38:38,759: training iter 492, loss=0.5117323398590088 (4.408979s)
INFO:niftynet:2019-02-11 15:38:47,500: training iter 493, loss=0.7389042973518372 (8.740617s)
INFO:niftynet:2019-02-11 15:38:48,744: training iter 494, loss=0.6751433610916138 (1.239239s)
INFO:niftynet:2019-02-11 15:38:55,893: training iter 495, loss=0.6455326080322266 (7.148180s)
INFO:niftynet:2019-02-11 15:38:57,720: training iter 496, loss=0.7238818407058716 (1.824776s)
INFO:niftynet:2019-02-11 15:39:05,473: training iter 497, loss=0.504889965057373 (7.752173s)
INFO:niftynet:2019-02-11 15:39:12,809: training iter 498, loss=0.5769439935684204 (7.335246s)
INFO:niftynet:2019-02-11 15:39:14,193: training iter 499, loss=0.4845428764820099 (1.383621s)
INFO:niftynet:2019-02-11 15:39:20,932: iter 500 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:39:20,934: training iter 500, loss=0.6523387432098389 (5.706994s)
INFO:niftynet:2019-02-11 15:39:22,062:     validation iter 500, loss=0.5024341344833374 (1.126696s)
INFO:niftynet:2019-02-11 15:39:28,978: training iter 501, loss=0.46431034803390503 (6.914052s)
INFO:niftynet:2019-02-11 15:39:30,214: training iter 502, loss=0.640454113483429 (1.236059s)
INFO:niftynet:2019-02-11 15:39:33,859: training iter 503, loss=0.6586496233940125 (3.644811s)
INFO:niftynet:2019-02-11 15:39:39,648: training iter 504, loss=0.6027388572692871 (5.787940s)
INFO:niftynet:2019-02-11 15:39:48,540: training iter 505, loss=0.5964599847793579 (8.889974s)
INFO:niftynet:2019-02-11 15:39:51,641: training iter 506, loss=0.714748203754425 (3.100038s)
INFO:niftynet:2019-02-11 15:39:55,281: training iter 507, loss=0.5006890296936035 (3.639334s)
INFO:niftynet:2019-02-11 15:40:03,237: training iter 508, loss=0.548389196395874 (7.955844s)
INFO:niftynet:2019-02-11 15:40:09,271: training iter 509, loss=0.6740158200263977 (6.033423s)
INFO:niftynet:2019-02-11 15:40:15,137: training iter 510, loss=0.5143245458602905 (5.865422s)
INFO:niftynet:2019-02-11 15:40:16,080:     validation iter 510, loss=0.5302894711494446 (0.940815s)
INFO:niftynet:2019-02-11 15:40:17,515: training iter 511, loss=0.5530438423156738 (1.433214s)
INFO:niftynet:2019-02-11 15:40:26,542: training iter 512, loss=0.6081054210662842 (9.026946s)
INFO:niftynet:2019-02-11 15:40:30,200: training iter 513, loss=0.5064473152160645 (3.657944s)
INFO:niftynet:2019-02-11 15:40:37,472: training iter 514, loss=0.5671144723892212 (7.271395s)
INFO:niftynet:2019-02-11 15:40:38,862: training iter 515, loss=0.6350906491279602 (1.387418s)
INFO:niftynet:2019-02-11 15:40:46,103: training iter 516, loss=0.7621650695800781 (7.238932s)
INFO:niftynet:2019-02-11 15:40:51,887: training iter 517, loss=0.6635545492172241 (5.784113s)
INFO:niftynet:2019-02-11 15:40:58,646: training iter 518, loss=0.514419436454773 (6.758087s)
INFO:niftynet:2019-02-11 15:41:02,440: training iter 519, loss=0.5379225015640259 (3.794224s)
INFO:niftynet:2019-02-11 15:41:03,646: training iter 520, loss=0.7387520670890808 (1.203391s)
INFO:niftynet:2019-02-11 15:41:14,149:     validation iter 520, loss=0.6042242050170898 (10.495114s)
INFO:niftynet:2019-02-11 15:41:16,739: training iter 521, loss=0.6449297070503235 (2.588082s)
INFO:niftynet:2019-02-11 15:41:24,236: training iter 522, loss=0.5518852472305298 (7.497596s)
INFO:niftynet:2019-02-11 15:41:28,950: training iter 523, loss=0.648573637008667 (4.712913s)
INFO:niftynet:2019-02-11 15:41:30,131: training iter 524, loss=0.4679264724254608 (1.180789s)
INFO:niftynet:2019-02-11 15:41:40,788: iter 525 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:41:40,793: training iter 525, loss=0.5586102604866028 (9.643986s)
INFO:niftynet:2019-02-11 15:41:42,988: training iter 526, loss=0.4567809998989105 (2.194851s)
INFO:niftynet:2019-02-11 15:41:44,101: training iter 527, loss=0.6496500968933105 (1.112106s)
INFO:niftynet:2019-02-11 15:41:47,924: training iter 528, loss=0.6078147292137146 (3.823010s)
INFO:niftynet:2019-02-11 15:41:56,388: training iter 529, loss=0.6321845650672913 (8.463669s)
INFO:niftynet:2019-02-11 15:42:08,232: training iter 530, loss=0.7353270053863525 (11.842582s)
INFO:niftynet:2019-02-11 15:42:09,282:     validation iter 530, loss=0.6492860317230225 (1.048466s)
INFO:niftynet:2019-02-11 15:42:10,698: training iter 531, loss=0.5955208539962769 (1.415392s)
INFO:niftynet:2019-02-11 15:42:11,946: training iter 532, loss=0.6100932359695435 (1.247620s)
INFO:niftynet:2019-02-11 15:42:18,497: training iter 533, loss=0.7298330664634705 (6.551164s)
INFO:niftynet:2019-02-11 15:42:24,564: training iter 534, loss=0.5123833417892456 (6.063497s)
INFO:niftynet:2019-02-11 15:42:34,031: training iter 535, loss=0.5775091052055359 (9.465273s)
INFO:niftynet:2019-02-11 15:42:36,470: training iter 536, loss=0.6100195050239563 (2.436651s)
INFO:niftynet:2019-02-11 15:42:39,534: training iter 537, loss=0.76753830909729 (3.062800s)
INFO:niftynet:2019-02-11 15:42:45,680: training iter 538, loss=0.6821025609970093 (6.145744s)
INFO:niftynet:2019-02-11 15:42:51,363: training iter 539, loss=0.5960943698883057 (5.682461s)
INFO:niftynet:2019-02-11 15:42:57,557: training iter 540, loss=0.7347167134284973 (6.192954s)
INFO:niftynet:2019-02-11 15:42:58,612:     validation iter 540, loss=0.707984447479248 (1.052617s)
INFO:niftynet:2019-02-11 15:43:01,468: training iter 541, loss=0.7293727397918701 (2.853096s)
INFO:niftynet:2019-02-11 15:43:09,101: training iter 542, loss=0.4918225109577179 (7.632754s)
INFO:niftynet:2019-02-11 15:43:13,234: training iter 543, loss=0.5494159460067749 (4.131269s)
INFO:niftynet:2019-02-11 15:43:22,506: training iter 544, loss=0.7032674551010132 (9.271774s)
INFO:niftynet:2019-02-11 15:43:23,752: training iter 545, loss=0.6720835566520691 (1.244063s)
INFO:niftynet:2019-02-11 15:43:33,555: training iter 546, loss=0.6010271310806274 (9.801011s)
INFO:niftynet:2019-02-11 15:43:34,792: training iter 547, loss=0.6381704807281494 (1.236765s)
INFO:niftynet:2019-02-11 15:43:41,464: training iter 548, loss=0.6657500267028809 (6.672008s)
INFO:niftynet:2019-02-11 15:43:42,478: training iter 549, loss=0.5749821066856384 (1.013997s)
INFO:niftynet:2019-02-11 15:43:46,215: iter 550 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:43:46,216: training iter 550, loss=0.5251902341842651 (2.724221s)
INFO:niftynet:2019-02-11 15:43:47,357:     validation iter 550, loss=0.5401702523231506 (1.139684s)
INFO:niftynet:2019-02-11 15:44:07,052: training iter 551, loss=0.5503891706466675 (19.692140s)
INFO:niftynet:2019-02-11 15:44:10,799: training iter 552, loss=0.6211210489273071 (3.746254s)
INFO:niftynet:2019-02-11 15:44:12,459: training iter 553, loss=0.7676820755004883 (1.660548s)
INFO:niftynet:2019-02-11 15:44:13,508: training iter 554, loss=0.62635338306427 (1.048437s)
INFO:niftynet:2019-02-11 15:44:24,781: training iter 555, loss=0.5907785296440125 (11.271826s)
INFO:niftynet:2019-02-11 15:44:33,635: training iter 556, loss=0.5551377534866333 (8.851732s)
INFO:niftynet:2019-02-11 15:44:35,426: training iter 557, loss=0.7043631076812744 (1.789982s)
INFO:niftynet:2019-02-11 15:44:36,721: training iter 558, loss=0.6166868209838867 (1.294129s)
INFO:niftynet:2019-02-11 15:44:49,395: training iter 559, loss=0.755033552646637 (12.667318s)
INFO:niftynet:2019-02-11 15:44:50,709: training iter 560, loss=0.7432407736778259 (1.311400s)
INFO:niftynet:2019-02-11 15:44:51,838:     validation iter 560, loss=0.5676096677780151 (1.126085s)
INFO:niftynet:2019-02-11 15:44:57,270: training iter 561, loss=0.4755023717880249 (5.427868s)
INFO:niftynet:2019-02-11 15:45:00,021: training iter 562, loss=0.5301743149757385 (2.750392s)
INFO:niftynet:2019-02-11 15:45:12,197: training iter 563, loss=0.5364401340484619 (12.174564s)
INFO:niftynet:2019-02-11 15:45:16,584: training iter 564, loss=0.7535328269004822 (4.387433s)
INFO:niftynet:2019-02-11 15:45:19,770: training iter 565, loss=0.6291812062263489 (3.184065s)
INFO:niftynet:2019-02-11 15:45:21,175: training iter 566, loss=0.6381987929344177 (1.397511s)
INFO:niftynet:2019-02-11 15:45:34,348: training iter 567, loss=0.6438330411911011 (13.173013s)
INFO:niftynet:2019-02-11 15:45:35,586: training iter 568, loss=0.5887576937675476 (1.238122s)
INFO:niftynet:2019-02-11 15:45:38,909: training iter 569, loss=0.5132050514221191 (3.322158s)
INFO:niftynet:2019-02-11 15:45:43,957: training iter 570, loss=0.5996686816215515 (5.046930s)
INFO:niftynet:2019-02-11 15:45:45,429:     validation iter 570, loss=0.7440474033355713 (1.471358s)
INFO:niftynet:2019-02-11 15:45:50,611: training iter 571, loss=0.6262824535369873 (5.179988s)
INFO:niftynet:2019-02-11 15:46:00,071: training iter 572, loss=0.6051446199417114 (9.459603s)
INFO:niftynet:2019-02-11 15:46:01,303: training iter 573, loss=0.6002713441848755 (1.231917s)
INFO:niftynet:2019-02-11 15:46:06,467: training iter 574, loss=0.49417760968208313 (5.164111s)
INFO:niftynet:2019-02-11 15:46:15,331: iter 575 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:46:15,332: training iter 575, loss=0.5182042121887207 (7.829422s)
INFO:niftynet:2019-02-11 15:46:20,451: training iter 576, loss=0.5724490880966187 (5.118813s)
INFO:niftynet:2019-02-11 15:46:21,719: training iter 577, loss=0.5334708094596863 (1.267631s)
INFO:niftynet:2019-02-11 15:46:25,999: training iter 578, loss=0.47578951716423035 (4.280175s)
INFO:niftynet:2019-02-11 15:46:35,909: training iter 579, loss=0.5749249458312988 (9.909539s)
INFO:niftynet:2019-02-11 15:46:42,634: training iter 580, loss=0.7490463256835938 (6.723115s)
INFO:niftynet:2019-02-11 15:46:43,801:     validation iter 580, loss=0.6447597146034241 (1.164772s)
INFO:niftynet:2019-02-11 15:46:45,576: training iter 581, loss=0.7488415241241455 (1.772981s)
INFO:niftynet:2019-02-11 15:46:46,667: training iter 582, loss=0.6578207015991211 (1.090536s)
INFO:niftynet:2019-02-11 15:46:58,911: training iter 583, loss=0.6286270618438721 (12.243657s)
INFO:niftynet:2019-02-11 15:47:02,974: training iter 584, loss=0.5230485200881958 (4.062342s)
INFO:niftynet:2019-02-11 15:47:06,716: training iter 585, loss=0.6502760648727417 (3.738649s)
INFO:niftynet:2019-02-11 15:47:07,829: training iter 586, loss=0.5749887228012085 (1.111934s)
INFO:niftynet:2019-02-11 15:47:21,163: training iter 587, loss=0.6097660064697266 (13.332456s)
INFO:niftynet:2019-02-11 15:47:25,594: training iter 588, loss=0.7016874551773071 (4.430681s)
INFO:niftynet:2019-02-11 15:47:26,831: training iter 589, loss=0.47006478905677795 (1.235667s)
INFO:niftynet:2019-02-11 15:47:28,171: training iter 590, loss=0.5928428173065186 (1.338331s)
INFO:niftynet:2019-02-11 15:47:29,172:     validation iter 590, loss=0.5679234266281128 (0.997845s)
INFO:niftynet:2019-02-11 15:47:42,249: training iter 591, loss=0.5596067905426025 (13.077134s)
INFO:niftynet:2019-02-11 15:47:45,179: training iter 592, loss=0.5956113338470459 (2.929241s)
INFO:niftynet:2019-02-11 15:47:46,858: training iter 593, loss=0.6864175200462341 (1.678450s)
INFO:niftynet:2019-02-11 15:47:52,354: training iter 594, loss=0.5624744296073914 (5.496198s)
INFO:niftynet:2019-02-11 15:48:03,066: training iter 595, loss=0.48860299587249756 (10.711022s)
INFO:niftynet:2019-02-11 15:48:06,639: training iter 596, loss=0.7447400093078613 (3.570676s)
INFO:niftynet:2019-02-11 15:48:07,846: training iter 597, loss=0.649020791053772 (1.206292s)
INFO:niftynet:2019-02-11 15:48:12,032: training iter 598, loss=0.6708556413650513 (4.184698s)
INFO:niftynet:2019-02-11 15:48:23,914: training iter 599, loss=0.5088057518005371 (11.882082s)
INFO:niftynet:2019-02-11 15:48:27,188: iter 600 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
INFO:niftynet:2019-02-11 15:48:27,188: training iter 600, loss=0.6483533978462219 (2.157725s)
INFO:niftynet:2019-02-11 15:48:28,259:     validation iter 600, loss=0.5634039640426636 (1.069583s)
INFO:niftynet:2019-02-11 15:48:33,129: training iter 601, loss=0.570875883102417 (4.869448s)
INFO:niftynet:2019-02-11 15:48:35,518: training iter 602, loss=0.7634521722793579 (2.388040s)
INFO:niftynet:2019-02-11 15:48:46,225: training iter 603, loss=0.6742689609527588 (10.705592s)
INFO:niftynet:2019-02-11 15:48:49,664: training iter 604, loss=0.5903696417808533 (3.438549s)
INFO:niftynet:2019-02-11 15:48:52,025: training iter 605, loss=0.4255836606025696 (2.359269s)
INFO:niftynet:2019-02-11 15:48:59,278: training iter 606, loss=0.649731457233429 (7.252894s)
INFO:niftynet:2019-02-11 15:49:04,608: training iter 607, loss=0.5747194290161133 (5.330293s)
INFO:niftynet:2019-02-11 15:49:12,119: training iter 608, loss=0.7266784906387329 (7.510145s)
INFO:niftynet:2019-02-11 15:49:13,497: training iter 609, loss=0.5884113907814026 (1.377254s)
INFO:niftynet:2019-02-11 15:49:21,144: training iter 610, loss=0.5621354579925537 (7.645212s)
INFO:niftynet:2019-02-11 15:49:22,271:     validation iter 610, loss=0.7118626832962036 (1.126363s)
INFO:niftynet:2019-02-11 15:49:28,512: training iter 611, loss=0.7330423593521118 (6.238345s)
INFO:niftynet:2019-02-11 15:49:30,002: training iter 612, loss=0.562836766242981 (1.489811s)
INFO:niftynet:2019-02-11 15:49:37,934: training iter 613, loss=0.5212372541427612 (7.931736s)
INFO:niftynet:2019-02-11 15:49:46,181: training iter 614, loss=0.4629075229167938 (8.246742s)
WARNING:niftynet:2019-02-11 15:49:50,687: User cancelled application
INFO:niftynet:2019-02-11 15:49:50,688: cleaning up...
INFO:niftynet:2019-02-11 15:49:50,688: stopping sampling threads
INFO:niftynet:2019-02-11 15:49:51,799: iter 615 saved: /home/sathiesh/niftynet_brain/models/brats/models/model.ckpt
WARNING:niftynet:2019-02-11 15:50:09,978: stopped early, incomplete iterations.
INFO:niftynet:2019-02-11 15:50:09,978: SegmentationApplication stopped (time in second 3511.27).

[T1]
csv_file = /home/sathiesh/niftynet_brain/csv/brats/hgg_lgg/orig_t1.csv
spatial_window_size = (96, 96, 96)
interp_order = 3 
pixdim = (1.0, 1.0, 1.0)
axcodes=(A, R, S)

[T1CE]
csv_file = /home/sathiesh/niftynet_brain/csv/brats/hgg_lgg/orig_t1ce.csv
spatial_window_size = (96, 96, 96)
interp_order = 3
pixdim = (1.0,1.0,1.0)
axcodes = (A, R, S)  


[T2]
csv_file = /home/sathiesh/niftynet_brain/csv/brats/hgg_lgg/orig_t2.csv
spatial_window_size = (96, 96, 96)
interp_order = 3
pixdim = (1.0,1.0,1.0)
axcodes = (A, R, S)  
[FLAIR]
csv_file = /home/sathiesh/niftynet_brain/csv/brats/hgg_lgg/orig_flair.csv
spatial_window_size = (96, 96, 96)
interp_order = 3
pixdim = (1.0,1.0,1.0)
axcodes = (A, R, S)  

[LABEL]
csv_file = /home/sathiesh/niftynet_brain/csv/brats/hgg_lgg/labels.csv
spatial_window_size = (96, 96, 96)
interp_order = 0
pixdim=(1.0, 1.0, 1.0)
axcodes=(A, R, S)

[SYSTEM]
cuda_devices = 0
num_threads = 8
num_gpus = 1
model_dir = /home/sathiesh/brats/models/hgg_lgg
dataset_split_file = /home/sathiesh/niftynet_brain/csv/brats/hgg_lgg/dataset_split.csv


[NETWORK]
window_sampling = weighted

name = dense_vnet
activation_function = leakyrelu
batch_size = 2
decay = 0.0
reg_type = L2
queue_length = 36
normalisation = False
whitening = True 
foreground_type = threshold_plus


[TRAINING]
lr = 0.001
loss_type = Dice
starting_iter = 0
save_every_n = 100
tensorboard_every_n = 5
max_iter = 6000
max_checkpoints = 200
validation_every_n = 1
exclude_fraction_for_validation = 0.1
exclude_fraction_for_inference = 0.1
rotation_angle = (-10.0, 10.0)
scaling_percentage = (-10.0, 10.0)

[INFERENCE]
inference_iter = -1
dataset_to_infer = all
save_seg_dir = /home/sathiesh/brats/hgg_lgg/inference 
output_interp_order = 0
spatial_window_size = (144, 144, 144) 

[EVALUATION]
evaluations = Dice
save_csv_dir = /home/sathiesh/brats/hgg_lgg/evaluation

[SEGMENTATION]
image = T1, T1CE, T2, FLAIR
label = LABEL
sampler= LABEL
output_prob = False
num_classes = 4
label_normalisation = True
